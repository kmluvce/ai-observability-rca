# ğŸ” AI Observability RCA System

**Generative AI-Driven Observability for Automated Root Cause Analysis in Modern IT Systems**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Ollama](https://img.shields.io/badge/Ollama-LLama3-orange.svg)](https://ollama.ai/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-0.4+-purple.svg)](https://www.trychroma.com/)

## ğŸš€ Overview

This system leverages **Generative AI** and **Retrieval-Augmented Generation (RAG)** to automatically analyze observability data (logs, metrics, traces) and generate comprehensive root cause analysis reports. Built with modern technologies including **Ollama/Llama3** for LLM capabilities and **ChromaDB** for vector storage.

### âœ¨ Key Features

- **ğŸ¤– AI-Powered RCA**: Automated root cause analysis using Llama3
- **ğŸ“Š Multi-Modal Analysis**: Processes logs, metrics, and traces together
- **ğŸ§  RAG Integration**: Learns from historical cases for better analysis
- **ğŸ“ Bulk Upload**: Support for bulk data ingestion (JSON, CSV, XLSX, TXT)
- **ğŸ” Similarity Search**: Find similar historical incidents
- **ğŸ“± Modern UI**: Clean, responsive web interface
- **ğŸš« No Docker Required**: Simple local installation and setup

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚â”€â”€â”€â”€â”‚  FastAPI Backend â”‚â”€â”€â”€â”€â”‚  Ollama/Llama3  â”‚
â”‚   (HTML/CSS/JS) â”‚    â”‚                 â”‚    â”‚      (LLM)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚    ChromaDB     â”‚
                       â”‚ (Vector Store)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§© Components

1. **Frontend**: Clean web interface for data input and results visualization
2. **FastAPI Backend**: RESTful API handling requests and orchestrating services
3. **LLM Service**: Integration with Ollama/Llama3 for text generation
4. **RAG Service**: Retrieval-augmented generation using ChromaDB
5. **RCA Service**: Core root cause analysis orchestration
6. **Database Layer**: ChromaDB for vector storage and similarity search

## ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Ollama** (for LLM capabilities)
- **Git** (for cloning the repository)

## ğŸ› ï¸ Quick Start

### 1. Install Ollama

```bash
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# Download from https://ollama.ai/download
```

### 2. Pull Llama3 Model

```bash
ollama pull llama3
```

### 3. Start Ollama Server

```bash
ollama serve
```

### 4. Clone and Setup Project

```bash
# Clone repository
git clone <repository-url>
cd ai-observability-rca

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 5. Run the System

```bash
python run.py
```

### 6. Access the Application

Open your browser to: **http://localhost:8000**

## ğŸ¯ Usage Guide

### ğŸ“Š Single Analysis

1. Navigate to the main page
2. Fill in the three text boxes:
   - **Logs**: Paste your application/system logs
   - **Metrics**: Paste performance metrics data
   - **Traces**: Paste distributed tracing data
3. Click **"Generate RCA Analysis"**
4. Review the generated root cause analysis
5. Optionally copy or download the results

### ğŸ“ Bulk Upload

1. Click on **"Bulk Upload"** in the navigation
2. Select files for each data type (JSON, CSV, XLSX, or TXT)
3. Click **"Upload Files"** to process in bulk
4. View upload results and database statistics

### ğŸ” Search Historical Cases

Use the search functionality to find similar past incidents and learn from historical patterns.

## ğŸ“ Project Structure

```
ai-observability-rca/
â”œâ”€â”€ backend/                    # Backend Python code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # FastAPI application
â”‚   â”œâ”€â”€ models/                # Data models and schemas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ services/              # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py     # Ollama/LLM integration
â”‚   â”‚   â”œâ”€â”€ rag_service.py     # RAG functionality
â”‚   â”‚   â””â”€â”€ rca_service.py     # RCA orchestration
â”‚   â”œâ”€â”€ database/              # Database layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chroma_db.py       # ChromaDB management
â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ frontend/                  # Frontend web interface
â”‚   â”œâ”€â”€ index.html            # Main RCA page
â”‚   â”œâ”€â”€ bulk_upload.html      # Bulk upload page
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ style.css     # Styling
â”‚       â””â”€â”€ js/
â”‚           â”œâ”€â”€ main.js       # Main page functionality
â”‚           â””â”€â”€ bulk_upload.js # Bulk upload functionality
â”œâ”€â”€ data/                     # Data storage
â”‚   â””â”€â”€ chroma_db/           # ChromaDB persistence
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup.py                # Installation script
â”œâ”€â”€ run.py                  # Main application runner
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file or set environment variables:

```bash
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3

# ChromaDB Configuration
CHROMA_DB_PATH=./data/chroma_db

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO
```

### Command Line Options

```bash
python run.py --help

Options:
  --host HOST       Host to bind to (default: 0.0.0.0)
  --port PORT       Port to bind to (default: 8000)
  --reload          Enable auto-reload for development
  --debug           Enable debug mode
  --workers NUM     Number of worker processes
  --log-level LEVEL Logging level (debug, info, warning, error)
```

## ğŸ“š API Documentation

Once running, visit **http://localhost:8000/docs** for interactive API documentation.

### Key Endpoints

- `POST /api/analyze` - Analyze observability data and generate RCA
- `POST /api/bulk-upload` - Bulk upload historical data
- `GET /api/search-similar` - Search for similar historical cases
- `GET /api/health` - Health check endpoint

## ğŸ§ª Example Data Formats

### Logs Example
```
2025-06-19 10:30:15 ERROR [ApplicationService] Database connection failed: timeout after 30s
2025-06-19 10:30:16 WARN [ConnectionPool] Retrying connection attempt 1/3
2025-06-19 10:30:18 ERROR [ConnectionPool] Connection attempt failed: Connection refused
```

### Metrics Example
```
timestamp,cpu_usage,memory_usage,disk_io,network_io
2025-06-19T10:30:00Z,85.2,78.5,120.3,45.7
2025-06-19T10:30:30Z,92.1,82.1,134.7,52.3
```

### Traces Example
```json
{
  "trace_id": "abc123def456",
  "spans": [
    {
      "span_id": "span001",
      "operation": "http_request",
      "duration_ms": 1250,
      "status": "error"
    }
  ]
}
```

## ğŸ› Troubleshooting

### Common Issues

1. **Ollama Connection Failed**
   ```bash
   # Check if Ollama is running
   curl http://localhost:11434/api/version
   
   # Start Ollama if not running
   ollama serve
   ```

2. **Llama3 Model Not Found**
   ```bash
   # Pull the model
   ollama pull llama3
   
   # List available models
   ollama list
   ```

3. **Port Already in Use**
   ```bash
   # Run on different port
   python run.py --port 8001
   ```

4. **ChromaDB Permission Issues**
   ```bash
   # Ensure data directory is writable
   chmod -R 755 data/
   ```

## ğŸ”’ Security Considerations

- **Development Only**: This setup is intended for development/testing
- **Production Deployment**: 
  - Use proper authentication
  - Set strong secret keys
  - Configure HTTPS
  - Implement rate limiting
  - Secure database access

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama Team** for the excellent LLM runtime
- **Meta** for the Llama3 model
- **ChromaDB** for vector database capabilities
- **FastAPI** for the robust web framework

## ğŸ“ Support

For support, questions, or feedback:

- ğŸ“§ Email: support@aiobservability.com
- ğŸ› Issues: [GitHub Issues](https://github.com/ai-observability/rca-system/issues)
- ğŸ“– Documentation: [Wiki](https://github.com/ai-observability/rca-system/wiki)

---

**â­ Star this repository if you find it helpful!**
